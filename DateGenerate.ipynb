{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate lane marker training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter the gradient on any or both axises\n",
    "def mag_thresh(img, sobel_kernel=3,sobel_axis='xy', mag_thresh=(50, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    if sobel_axis != 'xy':\n",
    "        if sobel_axis == 'x':\n",
    "            sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        elif sobel_axis == 'y':\n",
    "            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 1, ksize=sobel_kernel)\n",
    "    # Calculate the absolute value of sobelx\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Rescale to 8 bit\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(abs_sobel >= mag_thresh[0]) & (abs_sobel <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hls channel s threshold function\n",
    "def hls_select(img, thresh=(100, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    img_hls = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    s = np.array(img_hls[:,:,2])\n",
    "    # 3) Return a binary image of threshold result\n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output [(s>thresh[0])&(s<=thresh[1])] = 1 # placeholder line\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four source points for 0:00min - 1:18min\n",
    "src = np.float32(\n",
    "[[792,1036],\n",
    " [1802,1036],\n",
    " [1182,695],\n",
    " [1285,695]])\n",
    "\n",
    "# four desired points\n",
    "dst = np.float32(\n",
    "[[330,1080],\n",
    " [1350,1080],\n",
    " [330,0],\n",
    " [1350,0]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst,src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four source points for 1:18min - 5:00min\n",
    "src = np.float32(\n",
    "[[424,1041],\n",
    " [1400,1041],\n",
    " [900,693],\n",
    " [1033,693]])\n",
    "\n",
    "# four desired points\n",
    "dst = np.float32(\n",
    "[[274,1080],\n",
    " [1350,1080],\n",
    " [274,0],\n",
    " [1350,0]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst,src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warper(img, src, dst):\n",
    "\n",
    "    # Compute and apply perpective transform\n",
    "    img_size = (img.shape[1], img.shape[0]) \n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)  # keep same size as input image\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warp first then color thresh\n",
    "def image_warpbinary(image): \n",
    "    warp = warper(image,src,dst)\n",
    "    sx_binary = mag_thresh(warp, sobel_kernel=3,sobel_axis='x', mag_thresh=(60,255))\n",
    "    s_binary = hls_select(warp, thresh=(80, 255))\n",
    "    combined_binary = np.zeros_like(sx_binary)\n",
    "    combined_binary[(s_binary == 1) | (sx_binary == 1)] = 1\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_posxy_fit(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 12\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 100\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    left_fitx = np.int_(left_fitx)\n",
    "    right_fitx = np.int_(right_fitx)\n",
    "    #return left_fit,right_fit,left_fitx,right_fitx\n",
    "    #return left_fit,right_fit\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-50, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+50, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-55, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+55, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    \n",
    "    #Plot the polynomial lines onto the image\n",
    "    #plt.plot( left_fitx, ploty,linewidth=7, color='yellow')\n",
    "    #plt.plot( right_fitx, ploty,linewidth=7, color='yellow')\n",
    "    #window_img = plt.gcf()\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 1, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate ground truth image and visulize\n",
    "def drawresult(image,lane_warp):\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(lane_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marklane(image):\n",
    "    warp_image = image_warpbinary(image)\n",
    "    lane = find_posxy_fit(warp_image)\n",
    "    result = drawresult(image,lane)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gt(image):\n",
    "    warp_image = image_warpbinary(image)\n",
    "    lane_warp = find_posxy_fit(warp_image)\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(lane_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    return newwarp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate lane line mark video and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = './gts79_259.mp4'\n",
    "clip1 = VideoFileClip('./video 2_processed.mov').subclip(79,259)\n",
    "white_clip = clip1.fl_image(generate_gt) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is generating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip('./test.mp4').subclip(0,180)\n",
    "clip1.save_frame('./data/test.jpg',t=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_combine = VideoFileClip('./test79_259.mp4').subclip(0,300)\n",
    "clip_gt = VideoFileClip('./gts79_259.mp4').subclip(0,300)\n",
    "clip_img = VideoFileClip('./video 2_processed.mov').subclip(79,259)\n",
    "for i in range(174,179):\n",
    "    comimgpath = './Lanedata/Combine/img{0}.png'.format(i+79)\n",
    "    gtpath = './Lanedata/GT/gt{0}.png'.format(i+79)\n",
    "    imagepath = './Lanedata/IMG/images{0}.png'.format(i+79)\n",
    "    clip_combine.save_frame(comimgpath,t=i)\n",
    "    clip_gt.save_frame(gtpath,t=i)\n",
    "    clip_img.save_frame(imagepath,t=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 121.51\n",
    "comimgpath = './Lanedata/Combine/img{0}.png'.format(i+79)\n",
    "gtpath = './Lanedata/GT/gt{0}.png'.format(i+79)\n",
    "imagepath = './Lanedata/IMG/images{0}.png'.format(i+79)\n",
    "clip_combine.save_frame(comimgpath,t=i)\n",
    "clip_gt.save_frame(gtpath,t=i)\n",
    "clip_img.save_frame(imagepath,t=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_size):\n",
    "    imagefiles = sorted(glob.glob('./Lanedata/IMG/images*.png'))\n",
    "    gtfiles = sorted(glob.glob('./Lanedata/GT/gt*.png'))\n",
    "    images = []\n",
    "    gts = []\n",
    "    for image,gt in zip(imagefiles,gtfiles):\n",
    "        image = cv2.imread(image).astype(np.float32)\n",
    "        gt = cv2.imread(gt).astype(np.float32)\n",
    "        images.append(image)\n",
    "        gts.append(gt)\n",
    "        images.append(cv2.flip(image, 1))\n",
    "        gts.append(cv2.flip(gt, 1))\n",
    "    # prepare the training data\n",
    "    x_train = np.array(images)\n",
    "    y_train = np.array(gts)\n",
    "    background_color = (0,0,0)\n",
    "    images,gts = [],[]\n",
    "    for image,gt_image in zip(x_train,y_train):\n",
    "        image = scipy.misc.imresize(image, img_size)\n",
    "        gt_image = scipy.misc.imresize(gt_image, img_size)\n",
    "        #annotate ground truth\n",
    "        gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "        gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "        gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "        images.append(image)\n",
    "        gts.append(gt_image)\n",
    "\n",
    "    X_train,Y_train = np.array(images),np.array(gts)\n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 2\n",
    "#custimize the input image shape\n",
    "img_size = (540,960,3)\n",
    "X_train,Y_train = load_data(img_size)\n",
    "pickle.dump(X_train,open('X_lanetrain','wb'))\n",
    "pickle.dump(Y_train,open('Y_lanetrain','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
